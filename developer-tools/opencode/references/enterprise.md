# Opencode - Enterprise

**Pages:** 2

---

## Enterprise | OpenCode

**URL:** https://opencode.ai/docs/enterprise/

**Contents:**
- Enterprise
- Trial
  - Data handling
    - Sharing conversations
  - Code ownership
- Pricing
- Deployment
  - Central Config
  - SSO integration
  - Internal AI gateway

Using OpenCode securely in your organization.

OpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.

OpenCode does not store any of your code or context data.

To get started with OpenCode Enterprise:

OpenCode is open source and does not store any of your code or context data, so your developers can simply get started and carry out a trial.

OpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider.

This means that as long as you are using a provider you trust, or an internal AI gateway, you can use OpenCode securely.

The only caveat here is the optional /share feature.

If a user enables the /share feature, the conversation and the data associated with it are sent to the service we use to host these share pages at opencode.ai.

The data is currently served through our CDN’s edge network, and is cached on the edge near your users.

We recommend you disable this for your trial.

Learn more about sharing.

You own all code produced by OpenCode. There are no licensing restrictions or ownership claims.

We use a per-seat model for OpenCode Enterprise. If you have your own LLM gateway, we do not charge for tokens used. For further details about pricing and implementation options, contact us.

Once you have completed your trial and you are ready to use OpenCode at your organization, you can contact us to discuss pricing and implementation options.

We can set up OpenCode to use a single central config for your entire organization.

This centralized config can integrate with your SSO provider and ensures all users access only your internal AI gateway.

Through the central config, OpenCode can integrate with your organization’s SSO provider for authentication.

This allows OpenCode to obtain credentials for your internal AI gateway through your existing identity management system.

With the central config, OpenCode can also be configured to use only your internal AI gateway.

You can also disable all other AI providers, ensuring all requests go through your organization’s approved infrastructure.

While we recommend disabling the share pages to ensure your data never leaves your organization, we can also help you self-host them on your infrastructure.

This is currently on our roadmap. If you’re interested, let us know.

OpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.

Simply start with an internal trial with your team. OpenCode by default does not store your code or context data, making it easy to get started.

Then contact us to discuss pricing and implementation options.

We offer per-seat enterprise pricing. If you have your own LLM gateway, we do not charge for tokens used. For further details, contact us for a custom quote based on your organization’s needs.

Yes. OpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider. With central config and SSO integration, your data remains secure within your organization’s infrastructure.

OpenCode supports private npm registries through Bun’s native .npmrc file support. If your organization uses a private registry, such as JFrog Artifactory, Nexus, or similar, ensure developers are authenticated before running OpenCode.

To set up authentication with your private registry:

This creates ~/.npmrc with authentication details. OpenCode will automatically pick this up.

You must be logged into the private registry before running OpenCode.

Alternatively, you can manually configure a .npmrc file:

Developers must be logged into the private registry before running OpenCode to ensure packages can be installed from your enterprise registry.

**Examples:**

Example 1 (json):
```json
{  "$schema": "https://opencode.ai/config.json",  "share": "disabled"}
```

Example 2 (json):
```json
{  "$schema": "https://opencode.ai/config.json",  "share": "disabled"}
```

Example 3 (unknown):
```unknown
npm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/
```

Example 4 (unknown):
```unknown
npm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/
```

---

## Enterprise | OpenCode

**URL:** https://opencode.ai/docs/enterprise

**Contents:**
- Enterprise
- Trial
  - Data handling
    - Sharing conversations
  - Code ownership
- Pricing
- Deployment
  - Central Config
  - SSO integration
  - Internal AI gateway

Using OpenCode securely in your organization.

OpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.

OpenCode does not store any of your code or context data.

To get started with OpenCode Enterprise:

OpenCode is open source and does not store any of your code or context data, so your developers can simply get started and carry out a trial.

OpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider.

This means that as long as you are using a provider you trust, or an internal AI gateway, you can use OpenCode securely.

The only caveat here is the optional /share feature.

If a user enables the /share feature, the conversation and the data associated with it are sent to the service we use to host these share pages at opencode.ai.

The data is currently served through our CDN’s edge network, and is cached on the edge near your users.

We recommend you disable this for your trial.

Learn more about sharing.

You own all code produced by OpenCode. There are no licensing restrictions or ownership claims.

We use a per-seat model for OpenCode Enterprise. If you have your own LLM gateway, we do not charge for tokens used. For further details about pricing and implementation options, contact us.

Once you have completed your trial and you are ready to use OpenCode at your organization, you can contact us to discuss pricing and implementation options.

We can set up OpenCode to use a single central config for your entire organization.

This centralized config can integrate with your SSO provider and ensures all users access only your internal AI gateway.

Through the central config, OpenCode can integrate with your organization’s SSO provider for authentication.

This allows OpenCode to obtain credentials for your internal AI gateway through your existing identity management system.

With the central config, OpenCode can also be configured to use only your internal AI gateway.

You can also disable all other AI providers, ensuring all requests go through your organization’s approved infrastructure.

While we recommend disabling the share pages to ensure your data never leaves your organization, we can also help you self-host them on your infrastructure.

This is currently on our roadmap. If you’re interested, let us know.

OpenCode Enterprise is for organizations that want to ensure that their code and data never leaves their infrastructure. It can do this by using a centralized config that integrates with your SSO and internal AI gateway.

Simply start with an internal trial with your team. OpenCode by default does not store your code or context data, making it easy to get started.

Then contact us to discuss pricing and implementation options.

We offer per-seat enterprise pricing. If you have your own LLM gateway, we do not charge for tokens used. For further details, contact us for a custom quote based on your organization’s needs.

Yes. OpenCode does not store your code or context data. All processing happens locally or through direct API calls to your AI provider. With central config and SSO integration, your data remains secure within your organization’s infrastructure.

OpenCode supports private npm registries through Bun’s native .npmrc file support. If your organization uses a private registry, such as JFrog Artifactory, Nexus, or similar, ensure developers are authenticated before running OpenCode.

To set up authentication with your private registry:

This creates ~/.npmrc with authentication details. OpenCode will automatically pick this up.

You must be logged into the private registry before running OpenCode.

Alternatively, you can manually configure a .npmrc file:

Developers must be logged into the private registry before running OpenCode to ensure packages can be installed from your enterprise registry.

**Examples:**

Example 1 (json):
```json
{  "$schema": "https://opencode.ai/config.json",  "share": "disabled"}
```

Example 2 (json):
```json
{  "$schema": "https://opencode.ai/config.json",  "share": "disabled"}
```

Example 3 (unknown):
```unknown
npm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/
```

Example 4 (unknown):
```unknown
npm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/
```

---
